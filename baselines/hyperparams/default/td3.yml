#learning_rate: 0.001
#buffer_size: 1000000
#learning_starts: 5000
policy_kwargs: {
  net_arch:
    {
      pi: [400, 400, 400, 400],
      qf: [400, 400, 400]
    }
}
#batch_size: 256
#tau: 0.005
#gamma: 0.99
#train_freq: 1
#gradient_steps: -1
#policy_delay: 2
#optimize_memory_usage: False
#target_policy_noise: 0.5
#target_noise_clip: 1
#_init_setup_model: True
#seed: 53
#action_noise: None
#target_update_interval: 1
#target_entropy: Union[str, float] = "auto"
#use_sde: False # state dependent exploration
#sde_sample_freq: -1
#use_sde_at_warmup: False
  #policy: 'MlpPolicy'
gamma: 0.99
buffer_size: 1000000
#  noise_type: 'normal'
#  noise_std: 0.1
learning_starts: 10000
batch_size: 100
learning_rate: 0.001
train_freq: 1000
gradient_steps: 1000
#policy_kwargs: {layers: [400, 300]}
